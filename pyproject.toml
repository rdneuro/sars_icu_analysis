# =============================================================================
# SARS — SARS-CoV-2 Brain Connectivity Analysis Library
# =============================================================================
#
# Alternativa ao conda usando UV como gerenciador de pacotes.
#
# INSTALAÇÃO:
#   curl -LsSf https://astral.sh/uv/install.sh | sh   # instalar uv
#   uv sync                                             # instalar tudo
#   uv sync --extra gpu                                 # com CUDA (PyTorch GPU)
#   uv sync --extra full                                # absolutamente tudo
#   source .venv/bin/activate                           # ativar
#
# ADICIONAR PACOTE DEPOIS:
#   uv add <pacote>
#
# ATUALIZAR TUDO:
#   uv lock --upgrade && uv sync
#
# =============================================================================

[project]
name = "sars"
version = "0.1.0"
description = "SARS-CoV-2 Brain Connectivity Analysis Library — Multimodal neuroimaging analysis for post-ICU COVID-19 patients"
authors = [
    { name = "Velho Mago" },
]
license = { text = "MIT" }
readme = "README.md"
requires-python = ">=3.10,<3.13"
keywords = [
    "neuroimaging",
    "connectome",
    "reservoir-computing",
    "brain-networks",
    "fmri",
    "diffusion-mri",
    "covid-19",
    "criticality",
]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Science/Research",
    "Topic :: Scientific/Engineering :: Medical Science Apps.",
    "Topic :: Scientific/Engineering :: Bio-Informatics",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
]

# ─────────────────────────────────────────────────────────────────────────────
# DEPENDÊNCIAS CORE — Instaladas sempre com `uv sync`
# Cobre: config, data_io, esn.py, reservoir_dynamics.py, graph_analysis,
#         criticality (exceto GNNs), connectivity, covid_analysis, utils, viz
# ─────────────────────────────────────────────────────────────────────────────
dependencies = [
    # ── Scientific computing core ───────────────────────────────────────
    "numpy>=1.24,<2.0",              # Pinado <2.0 por compatibilidade com nilearn/dipy
    "scipy>=1.10",
    "pandas>=2.0",
    "scikit-learn>=1.3",
    "statsmodels>=0.14",
    "h5py>=3.8",

    # ── Neuroimaging ────────────────────────────────────────────────────
    "nibabel>=5.0",
    "nilearn>=0.10",

    # ── Network / graph analysis ────────────────────────────────────────
    "networkx>=3.1",
    "bctpy>=0.6",                    # Brain Connectivity Toolbox (Python)

    # ── Reservoir computing ─────────────────────────────────────────────
    "reservoirpy>=0.4",              # Backend ESN (opcional mas altamente recomendado)

    # ── Visualization ───────────────────────────────────────────────────
    "matplotlib>=3.7",
    "seaborn>=0.12",
    "plotly>=5.15",                  # Dashboards interativos

    # ── Utilities ───────────────────────────────────────────────────────
    "tqdm>=4.65",
    "joblib>=1.3",
    "pyyaml>=6.0",
    "jinja2>=3.1",
]

# ─────────────────────────────────────────────────────────────────────────────
# EXTRAS OPCIONAIS — Instalados sob demanda
# ─────────────────────────────────────────────────────────────────────────────
[project.optional-dependencies]

# GPU — PyTorch + PyG com CUDA
# Uso: uv sync --extra gpu
gpu = [
    "torch>=2.2",
    "torch-geometric>=2.5",
    "torch-scatter",
    "torch-sparse",
]

# Diffusion MRI analysis (pipeline de dMRI já processou, mas útil para reanalises)
# Uso: uv sync --extra diffusion
diffusion = [
    "dipy>=1.9",
    "dmri-amico>=2.0",
    "fury>=0.10",                    # Visualização 3D tractografia
]

# Relatórios e exportação
# Uso: uv sync --extra reports
reports = [
    "fpdf2>=2.7",
    "openpyxl>=3.1",                 # Export Excel
    "xlsxwriter>=3.1",
    "nbformat>=5.9",                 # Export notebooks
    "nbconvert>=7.0",
]

# Desenvolvimento e testes
# Uso: uv sync --extra dev
dev = [
    "pytest>=7.4",
    "pytest-cov>=4.1",
    "ruff>=0.4",                     # Linter ultrarrápido (mesmo dev do uv — Astral)
    "mypy>=1.5",
    "ipython>=8.14",
    "ipykernel>=6.25",               # Kernel para Jupyter/Spyder
    "jupyter>=1.0",
    "sphinx>=7.0",
    "sphinx-rtd-theme>=1.3",
]

# Tudo junto
# Uso: uv sync --extra full
full = [
    "sars[gpu,diffusion,reports,dev]",
]

# ─────────────────────────────────────────────────────────────────────────────
# ENTRY POINTS (scripts CLI)
# ─────────────────────────────────────────────────────────────────────────────
[project.scripts]
sars-check = "sars.utils.atlas_manager:check_installation"

# =============================================================================
# UV CONFIGURATION
# =============================================================================
[tool.uv]
# PyTorch CUDA wheels — o uv baixa daqui automaticamente
extra-index-url = [
    "https://download.pytorch.org/whl/cu124",
]
# Resolutor: usar a versão mais recente compatível
resolution = "highest"

# =============================================================================
# BUILD SYSTEM
# =============================================================================
[build-system]
requires = ["hatchling>=1.18"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["sars"]

# =============================================================================
# TOOL CONFIGURATIONS
# =============================================================================

# ── Ruff (linter + formatter — substitui flake8, black, isort) ──────────
[tool.ruff]
target-version = "py310"
line-length = 100

[tool.ruff.lint]
select = [
    "E",    # pycodestyle errors
    "W",    # pycodestyle warnings
    "F",    # pyflakes
    "I",    # isort
    "N",    # pep8-naming
    "UP",   # pyupgrade
    "B",    # flake8-bugbear
    "SIM",  # flake8-simplify
    "NPY",  # numpy-specific
]
ignore = [
    "E501",  # line too long (formatter cuida)
    "B905",  # zip strict (Python 3.10+)
    "SIM108", # ternary (nem sempre mais legível)
    "N803",  # argument name uppercase (SC, FC, W são padrão em neurociência)
    "N806",  # variable name uppercase (idem)
]

[tool.ruff.lint.isort]
known-first-party = ["sars"]
section-order = ["future", "standard-library", "third-party", "first-party", "local-folder"]

# ── Pytest ──────────────────────────────────────────────────────────────
[tool.pytest.ini_options]
testpaths = ["tests"]
addopts = [
    "-v",
    "--tb=short",
    "--strict-markers",
    "-x",                            # Para no primeiro erro
]
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "gpu: marks tests requiring GPU",
    "data: marks tests requiring real patient data",
]

# ── Mypy ────────────────────────────────────────────────────────────────
[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
ignore_missing_imports = true        # Muitos pacotes neuroimaging sem stubs
